{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdsdqyL3zgcPU3qgaDZF9E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranjita782/python-projects/blob/main/loantap2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lbQD7ujV_UK",
        "outputId": "b5939e8a-1323-4edb-e07b-3728793db45c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZPYj7CZCfxntE8p2Lze_4QO4MyEOy6_d\n",
            "To: /content/logistic_regression.csv\n",
            "100% 100M/100M [00:04<00:00, 21.3MB/s] \n"
          ]
        }
      ],
      "source": [
        "!gdown 1ZPYj7CZCfxntE8p2Lze_4QO4MyEOy6_d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Header files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import gdown as gd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "lGU56PYvWEfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the dataset\n",
        "data = pd.read_csv('logistic_regression.csv')"
      ],
      "metadata": {
        "id": "0jDPjYULWLB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of imputation for emp_title\n",
        "data['emp_title'].fillna('Unknown', inplace=True)\n",
        "\n",
        "data['emp_length'].fillna('Unknown', inplace=True)\n"
      ],
      "metadata": {
        "id": "jmYp-EjkXIqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['revol_util'].fillna(data['revol_util'].median(), inplace=True)\n"
      ],
      "metadata": {
        "id": "QvUhnQS_X1Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of correlation-based imputation\n",
        "total_acc_avg = data.groupby('total_acc')['mort_acc'].mean()\n",
        "data['mort_acc'] = data.apply(lambda x: total_acc_avg[x['total_acc']] if pd.isnull(x['mort_acc']) else x['mort_acc'], axis=1)\n"
      ],
      "metadata": {
        "id": "lxKyCvk5X4BE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['pub_rec_bankruptcies'].fillna(0, inplace=True)\n"
      ],
      "metadata": {
        "id": "4LUrXUXgYBn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['mort_acc_missing'] = data['mort_acc'].isnull().astype(int)\n"
      ],
      "metadata": {
        "id": "8Z3WnzkLYIrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['term', 'grade', 'sub_grade', 'home_ownership'], drop_first=True)\n",
        "\n",
        "# Example of scaling numerical features\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "numeric_features = ['loan_amnt', 'int_rate', 'installment', 'annual_inc', 'dti', 'open_acc', 'revol_bal', 'revol_util', 'total_acc', 'mort_acc', 'pub_rec_bankruptcies']\n",
        "data[numeric_features] = scaler.fit_transform(data[numeric_features])\n"
      ],
      "metadata": {
        "id": "iRXcsGx8YUHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['issue_d'] = pd.to_datetime(data['issue_d'])\n",
        "data['issue_year'] = data['issue_d'].dt.year\n",
        "data['issue_month'] = data['issue_d'].dt.month\n"
      ],
      "metadata": {
        "id": "-e5UpRxrafBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.get_dummies(data, columns=['purpose'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "DnottfFsan45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['earliest_cr_line'] = pd.to_datetime(data['earliest_cr_line'])\n",
        "data['credit_age'] = (data['issue_d'] - data['earliest_cr_line']).dt.days // 30  # in months\n"
      ],
      "metadata": {
        "id": "o2hfpEXiazER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['initial_list_status'] = data['initial_list_status'].map({'w': 0, 'f': 1})\n"
      ],
      "metadata": {
        "id": "CIfO53SOa3nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['zip_code'] = data['address'].apply(lambda x: x[-5:])  # Assuming ZIP is the last 5 characters\n",
        "data = pd.get_dummies(data, columns=['zip_code'], drop_first=True)\n"
      ],
      "metadata": {
        "id": "hflDwv8na60D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numeric columns\n",
        "numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Exclude non-numeric columns\n",
        "non_numeric_columns = data.columns.difference(numeric_columns)\n",
        "\n",
        "# Option 1: Scale only the numeric columns\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data[numeric_columns])\n",
        "\n",
        "# Convert back to a DataFrame and retain non-numeric columns\n",
        "data_scaled_df = pd.DataFrame(data_scaled, columns=numeric_columns)\n",
        "final_data = pd.concat([data_scaled_df, data[non_numeric_columns].reset_index(drop=True)], axis=1)\n",
        "\n",
        "# Option 2: If you want to retain non-numeric columns unchanged\n",
        "# You might prefer to scale only numeric columns and then concatenate with the rest\n"
      ],
      "metadata": {
        "id": "oEGHxL0hb53w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of encoding (if grouping or simplification is not performed):\n",
        "data['emp_title'] = data['emp_title'].astype('category').cat.codes\n"
      ],
      "metadata": {
        "id": "EWf6mdrcdFc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
        "data['emp_length'] = mode_imputer.fit_transform(data[['emp_length']]).astype(str)\n",
        "data['title'] = mode_imputer.fit_transform(data[['title']]).astype(str)\n"
      ],
      "metadata": {
        "id": "ulTrv4y8dYbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title_counts = data['title'].value_counts()\n",
        "data['title_encoded'] = data['title'].map(title_counts)\n"
      ],
      "metadata": {
        "id": "8Oh0SgFjfYGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map loan_status to numeric values\n",
        "data['loan_status'] = data['loan_status'].map({'Fully Paid': 0, 'Charged Off': 1})"
      ],
      "metadata": {
        "id": "bsokYHzXgGhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the mean of the target variable for each title\n",
        "target_mean = data.groupby('title')['loan_status'].mean()\n",
        "\n",
        "\n",
        "# Map these means to the original data\n",
        "data['title'] = data['title'].map(target_mean)\n"
      ],
      "metadata": {
        "id": "CGWC9I8ZgJJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming `loan_status` has already been converted to numeric (0 and 1)\n",
        "emp_title_mean = data.groupby('emp_title')['loan_status'].mean()\n",
        "data['emp_title'] = data['emp_title'].map(emp_title_mean)\n"
      ],
      "metadata": {
        "id": "GdWw-KdSjBAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency encoding\n",
        "emp_title_freq = data['emp_title'].value_counts(normalize=True)\n",
        "data['emp_title'] = data['emp_title'].map(emp_title_freq)\n"
      ],
      "metadata": {
        "id": "3zSDSdxxjEOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['address'], axis=1)\n"
      ],
      "metadata": {
        "id": "2pTJ_UNuldvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding to the application_type column\n",
        "data['application_type'] = label_encoder.fit_transform(data['application_type'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VV_HQKCsmj6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting features from datetime columns\n",
        "data['issue_year'] = data['issue_d'].dt.year\n",
        "data['issue_month'] = data['issue_d'].dt.month\n",
        "\n",
        "# Drop original datetime column if not needed\n",
        "data = data.drop(columns=['issue_d'])\n"
      ],
      "metadata": {
        "id": "E6LVgv3foBkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting features from datetime columns\n",
        "data['earliest_cr_line_year'] = data['earliest_cr_line'].dt.year\n",
        "data['earliest_cr_line_month'] = data['earliest_cr_line'].dt.month\n",
        "data = data.drop(columns=['earliest_cr_line'])"
      ],
      "metadata": {
        "id": "AZiocuUkDgxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Apply label encoding\n",
        "data['application_type'] = label_encoder.fit_transform(data['application_type'])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YRroBD-pCo1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isnull().sum()\n",
        "print(missing_values[missing_values > 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EICXTgf7kdPV",
        "outputId": "408881ce-a083-4990-df4e-7a4e260c9c09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_length_mapping = {\n",
        "    'Unknown': 0,\n",
        "    '< 1 year': 1,\n",
        "    '1 year': 2,\n",
        "    '2 years': 3,\n",
        "    '3 years': 4,\n",
        "    '4 years': 5,\n",
        "    '5 years': 6,\n",
        "    '6 years': 7,\n",
        "    '7 years': 8,\n",
        "    '8 years': 9,\n",
        "    '9 years': 10,\n",
        "    '10+ years': 11\n",
        "}\n",
        "\n",
        "data['emp_length'] = data['emp_length'].map(emp_length_mapping)\n"
      ],
      "metadata": {
        "id": "zv3EkBPHFVtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['verification_status'] = data['verification_status'].map({'Not Verified': 0, 'Source Verified': 1, 'Verified': 2})"
      ],
      "metadata": {
        "id": "vkIibLBEmJs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_values = data.isnull().sum()\n",
        "print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN8w5IyaF9In",
        "outputId": "8e86165a-1c0d-4dd7-af12-265b0640f8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns with missing values:\n",
            " Series([], dtype: int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('preprocessed_data.csv', index=False)"
      ],
      "metadata": {
        "id": "d3yyiM4T36m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_pickle('preprocessed_data.pkl')\n",
        "data = pd.read_pickle('preprocessed_data.pkl')"
      ],
      "metadata": {
        "id": "Em9suvSulkVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('preprocessed_data.csv')"
      ],
      "metadata": {
        "id": "NSZhb13D6w2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only the numerical features from your data\n",
        "numerical_data = data.select_dtypes(include=['float64', 'int64'])\n"
      ],
      "metadata": {
        "id": "PFsuJ7EB7iAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.e.1 VIF calculation to check Multicollinearity\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Create a DataFrame to store VIF values\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data['Feature'] = numerical_data.columns\n",
        "\n",
        "# Calculate VIF for each feature\n",
        "vif_data['VIF'] = [variance_inflation_factor(numerical_data.values, i) for i in range(numerical_data.shape[1])]\n",
        "\n",
        "# Display the VIF values\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41sQTBD67mNc",
        "outputId": "e04401a9-a100-476d-cfa2-7fbb5236c05b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Feature           VIF\n",
            "0                loan_amnt  1.200614e+01\n",
            "1                 int_rate  1.299249e+00\n",
            "2              installment  1.149836e+01\n",
            "3                emp_title  2.231637e+00\n",
            "4               emp_length  4.182939e+00\n",
            "5               annual_inc  1.244228e+00\n",
            "6      verification_status  3.059915e+00\n",
            "7              loan_status  1.657010e+00\n",
            "8                    title  3.768521e+00\n",
            "9                      dti  1.055770e+00\n",
            "10                open_acc  2.086534e+00\n",
            "11                 pub_rec  2.202657e+00\n",
            "12               revol_bal  1.339278e+00\n",
            "13              revol_util  1.248655e+00\n",
            "14               total_acc  2.388642e+00\n",
            "15     initial_list_status  2.786293e+00\n",
            "16        application_type  5.602120e+02\n",
            "17                mort_acc  1.380251e+00\n",
            "18    pub_rec_bankruptcies  2.002558e+00\n",
            "19        mort_acc_missing           NaN\n",
            "20              issue_year  7.078661e+09\n",
            "21             issue_month  6.679240e+02\n",
            "22              credit_age  5.216722e+05\n",
            "23           title_encoded  2.302764e+00\n",
            "24   earliest_cr_line_year  6.968566e+09\n",
            "25  earliest_cr_line_month  7.017599e+02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation of VIF Results\n",
        "\n",
        "---\n",
        "VIF for loan_amnt (**12.00**): Indicates significant multicollinearity. This variable might be highly correlated with other features like installment.\n",
        "\n",
        "VIF for installment (**11.50**): Also shows significant multicollinearity, likely due to its close relationship with loan_amnt.\n",
        "\n",
        "VIF for application_type (**560.21**): Extremely high VIF, suggesting severe multicollinearity. This feature may be highly redundant.\n",
        "\n",
        "VIF for issue_year and earliest_cr_line_year: Extremely high VIF values (in billions), indicating severe multicollinearity. These features are likely highly correlated with each other or other features related to time.\n",
        "\n",
        "VIF for credit_age (**521,672.20**): This is another example of extreme multicollinearity, which suggests that it’s highly correlated with other time-related variables.\n",
        "\n",
        "Features with VIF close to 1: These features, like **dti, annual_inc, and int_rate, show low multicollinearity and are generally safe to keep in the model.**\n",
        "\n",
        "We plan to go ahead with Recursive feature elimination which eliminates  remove less important features and select the ones that contribute most to our model’s performance.\n"
      ],
      "metadata": {
        "id": "4iBSPpJ5DQSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.e.2 RFE Implementation\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X = data.drop(columns=['loan_status'])  # Replace 'target_variable' with the actual target column\n",
        "y = data['loan_status']  # Replace 'target_variable' with the actual target column\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "NjWx5NQe8PNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = LogisticRegression()\n"
      ],
      "metadata": {
        "id": "cd1OzASl93_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize RFE with the model and specify the number of features to select\n",
        "rfe = RFE(model, n_features_to_select=10)\n"
      ],
      "metadata": {
        "id": "CF2uo6w-968q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit RFE\n",
        "rfe = rfe.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "lI-Oo_r5-B6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the selected features\n",
        "selected_features = X_train.columns[rfe.support_]\n",
        "print(\"Selected Features by RFE:\", selected_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opws_f6G-Dzb",
        "outputId": "2dcefdd0-a3aa-42fc-fb3a-f205a55c4458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features by RFE: Index(['emp_title', 'title', 'zip_code_11650', 'zip_code_22690',\n",
            "       'zip_code_29597', 'zip_code_30723', 'zip_code_48052', 'zip_code_70466',\n",
            "       'zip_code_86630', 'zip_code_93700'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The features selected by RFE are those that the model has determined to have the most predictive power. In our case, features like **emp_title**, **title**, and specific **zip_code** variables were retained because they were deemed most relevant to predicting the target variable.\n",
        "\n",
        "Model Simplification: By reducing the number of features, RFE simplifies the model, making it easier to interpret and faster to compute, while maintaining (or even improving) model performance."
      ],
      "metadata": {
        "id": "XUSxuMvkB88D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoders = {}\n",
        "ordinal_cols = []  # Specify ordinal columns if any\n",
        "for col in ordinal_cols:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le"
      ],
      "metadata": {
        "id": "mEVgMZI-BUty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nominal_cols = ['term', 'grade', 'sub_grade', 'home_ownership',\n",
        "                'verification_status', 'purpose', 'initial_list_status',\n",
        "                'application_type', 'emp_title']  # Modify as needed\n",
        "for col in nominal_cols:\n",
        "    if col in data.columns and data[col].dtype == 'object':\n",
        "        data[col] = data[col].str.strip()\n"
      ],
      "metadata": {
        "id": "eDs2Ah12Ca2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation between Loan Amount and Installment\n",
        "correlation = data['loan_amnt'].corr(data['installment'])\n",
        "correlation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bfFVJEqHr2p",
        "outputId": "509c0b3b-bb94-487c-ed40-c817083d1186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9539289082616188"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value 0.95 suggests that higher loan amounts tend to have higher installments."
      ],
      "metadata": {
        "id": "PymrZ4B8H3fm"
      }
    }
  ]
}